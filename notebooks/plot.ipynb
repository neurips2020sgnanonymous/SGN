{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook \n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute shortest lenght across runs\n",
    "def min_length(path, folder_name, parameter, n_runs, algorithm):\n",
    "\n",
    "    lengths = []\n",
    "\n",
    "    for run in range(n_runs):\n",
    "\n",
    "        subfolder_name = 'res_{}_{}_{}'.format(algorithm, parameter, run+1)\n",
    "       \n",
    "        with open(os.path.join(path, folder_name, subfolder_name, 'results.json')) as f:\n",
    "\n",
    "            data = json.load(f)\n",
    "\n",
    "        f.close()\n",
    "\n",
    "        lengths.append(len(data['avg_loss']))\n",
    "\n",
    "    return min(lengths)\n",
    "\n",
    "def averaged_res(path, folder_name, parameter, n_runs, min_length, algorithm):\n",
    "\n",
    "    for run in range(n_runs):\n",
    "    \n",
    "        subfolder_name = 'res_{}_{}_{}'.format(algorithm, parameter, run+1)\n",
    "       \n",
    "        with open(os.path.join(path, folder_name, subfolder_name, 'results.json')) as f:\n",
    "\n",
    "            data = json.load(f)\n",
    "\n",
    "        f.close()\n",
    "\n",
    "        if run+1 == 1:\n",
    "            \n",
    "            loss = np.asarray(data['avg_loss'])[:min_length]\n",
    "            \n",
    "            try:\n",
    "                test = np.asarray(data['test_loss'])[:min_length]\n",
    "            except:\n",
    "                test = np.asarray(data['test_acc'])[:min_length]\n",
    "            \n",
    "            tot_time = np.asarray(data['tot_time'])\n",
    "\n",
    "        else:\n",
    "\n",
    "            loss += np.asarray(data['avg_loss'])[:min_length]\n",
    "            \n",
    "            try:\n",
    "                test += np.asarray(data['test_loss'])[:min_length]\n",
    "            except:\n",
    "                test += np.asarray(data['test_acc'])[:min_length]\n",
    "           \n",
    "            tot_time += np.asarray(data['tot_time'])\n",
    "\n",
    "    return loss/n_runs, tot_time/n_runs, test/n_runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define parameters\n",
    "data = 'fashion'\n",
    "path = '../results'\n",
    "snap_sec = 150\n",
    "n_runs = 5\n",
    "lr_s = [0.1, 0.01, 0.001]\n",
    "cg_iterations = [10, 5, 3, 2]\n",
    "loc=leg_location = 3\n",
    "y_range = (10**-2, 3*10**4)\n",
    "epochs_range = (0, 10)\n",
    "sec_range = (0, 250)\n",
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.figure(2)\n",
    "plt.figure(3)\n",
    "plt.figure(4)\n",
    "\n",
    "for lr in lr_s:\n",
    "    #compute min common lenght\n",
    "    length_sgd = min_length(path, data, lr, n_runs, 'SGD')\n",
    "    sgd_loss, sgd_time, sgd_testloss = averaged_res(path, data, lr, n_runs, length_sgd, 'SGD')\n",
    "    sgd_epochs = np.asarray(range(1, len(sgd_loss)+1))\n",
    "    sgd_time_per_epoch = sgd_epochs*(sgd_time/len(sgd_loss))\n",
    "    plt.figure(1)\n",
    "    plt.plot(sgd_epochs, sgd_loss, label='SGD, lr {}'.format(lr))\n",
    "    plt.figure(2)\n",
    "    plt.plot(sgd_time_per_epoch, sgd_loss, label='SGD, lr {}'.format(lr))\n",
    "    plt.figure(3)\n",
    "    plt.plot(sgd_epochs, sgd_testloss, label='SGD, lr {}'.format(lr))\n",
    "    plt.figure(4)\n",
    "    plt.plot(sgd_time_per_epoch, sgd_testloss, label='SGD, lr {}'.format(lr))\n",
    "    if data in ['mnist', 'fashion', 'cifar10']:\n",
    "        idx = int(snap_sec/(sgd_time/len(sgd_loss)))\n",
    "        print('sgd {} test acc {}, epoch {}, time {}'.format(lr, sgd_testloss[idx-1], idx, sgd_time_per_epoch[idx-1]))\n",
    "for cg_iter in cg_iterations:\n",
    "    #compute min common lenght\n",
    "    length_sgn = min_length(path, data, cg_iter, n_runs, 'SGN')\n",
    "    sgn_loss, sgn_time, sgn_testloss = averaged_res(path, data, cg_iter, n_runs, length_sgn, 'SGN')\n",
    "    sgn_epochs = np.asarray(range(1, len(sgn_loss)+1))\n",
    "    sgn_time_per_epoch = sgn_epochs*(sgn_time/len(sgn_loss))\n",
    "    plt.figure(1)\n",
    "    plt.plot(sgn_epochs, sgn_loss, label='SGN, cg iter {}'.format(cg_iter), linestyle='dashed')\n",
    "    plt.figure(2)\n",
    "    plt.plot(sgn_time_per_epoch, sgn_loss, label='SGN, cg iter {}'.format(cg_iter), linestyle='dashed')\n",
    "    plt.figure(3)\n",
    "    plt.plot(sgn_epochs, sgn_testloss, label='SGN, cg iter {}'.format(cg_iter), linestyle='dashed')\n",
    "    plt.figure(4)\n",
    "    plt.plot(sgn_time_per_epoch, sgn_testloss, label='SGN, cg iter {}'.format(cg_iter), linestyle='dashed')\n",
    "    if data in ['mnist', 'fashion', 'cifar10']:\n",
    "        idx = int(snap_sec/(sgn_time/len(sgn_loss)))\n",
    "        print('sgn {} test acc {}, epoch {}, time {}'.format(cg_iter, sgn_testloss[idx-1], idx, sgn_time_per_epoch[idx-1]))\n",
    "    \n",
    "plt.figure(1)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, which=\"both\", ls=\"-\")\n",
    "plt.legend(loc=leg_location)\n",
    "plt.ylim(y_range)\n",
    "plt.xlim(epochs_range)\n",
    "if save:\n",
    "    plt.savefig('{}_loss_epochs.svg'.format(data), format='svg', dpi=1200)\n",
    "\n",
    "\n",
    "plt.figure(2)\n",
    "plt.xlabel('sec')\n",
    "plt.ylabel('loss')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, which=\"both\", ls=\"-\")\n",
    "plt.legend(loc=leg_location)\n",
    "plt.ylim(y_range)\n",
    "plt.xlim(sec_range)\n",
    "if save:\n",
    "    plt.savefig('{}_loss_time.svg'.format(data), format='svg', dpi=1200)\n",
    "\n",
    "\n",
    "plt.figure(3)\n",
    "plt.xlabel('epochs')\n",
    "plt.grid(True, which=\"both\", ls=\"-\")\n",
    "plt.legend(loc=leg_location)\n",
    "if data in ['boston', 'sine_10', 'sine_100']:\n",
    "    plt.ylabel('test loss')\n",
    "    plt.ylim(y_range)\n",
    "    plt.xlim(epochs_range)\n",
    "    plt.yscale('log')\n",
    "    if save:\n",
    "        plt.savefig('{}_testloss_epochs.svg'.format(data), format='svg', dpi=1200)\n",
    "else:\n",
    "    plt.ylabel('test acc')\n",
    "    plt.ylim((0,1))\n",
    "    plt.xlim(epochs_range)\n",
    "    if save:\n",
    "        plt.savefig('{}_testacc_epochs.svg'.format(data), format='svg', dpi=1200)\n",
    "\n",
    "plt.figure(4)\n",
    "plt.xlabel('sec')\n",
    "plt.grid(True, which=\"both\", ls=\"-\")\n",
    "plt.legend(loc=leg_location)\n",
    "if data in ['boston', 'sine_10', 'sine_100']:\n",
    "    plt.ylabel('test loss')\n",
    "    plt.ylim(y_range)\n",
    "    plt.xlim(sec_range)\n",
    "    plt.yscale('log')\n",
    "    if save:\n",
    "        plt.savefig('{}_testloss_time.svg'.format(data), format='svg', dpi=1200)\n",
    "else:\n",
    "    plt.ylabel('test acc')\n",
    "    plt.ylim((0,1))\n",
    "    plt.xlim(sec_range)\n",
    "    if save:\n",
    "        plt.savefig('{}_testacc_time.svg'.format(data), format='svg', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
